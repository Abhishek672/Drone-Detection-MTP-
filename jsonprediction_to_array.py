# -*- coding: utf-8 -*-
"""jsonprediction_to_array.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/107TPzuZsyj759wTwIlPkdYfdDnLNwpMo
"""

import json
from PIL import Image
import numpy as np
import os

def get_data(distros_dict):

  '''
  Takes json.load() object which contains the prediction of bounding boxes done by model on test dataset
  The json file has information about the path, name and predicted bounding boxes for each test image
  The test data should be annotated with .txt

  return the ground truth and predicted bounding boxes for each image in the test set
  '''
  #Nx?x5 -- N-number of test images , #?-gt bboxes present in that image , 5- {class, xmin, ymin, xmax, ymax}
  gt_bboxes = [] 

  #Nx?x6  --N - Number of test images , ?- bboxes predicted for an image , 6 -{ xmin, ymin, xmax, ymax, conf, class}
  pred_bboxes = [] 

  # For every frame / every image
  for distro in distros_dict:
    #get the path of the test image in .jpg/.jpeg...
    filename = distro['filename']

    #get the Width and height of the test image..
    Image_Width, Image_Height = Image.open(filename).size
        
    #stores the ground truth bboxes and predicted bboxes 
    #for the given image..[[class,xmin,ymin,xmax,ymax],[...]]
    cur_img_gt_bboxes = []
    cur_img_pred_bboxes = []

    #Get the ground truth bounding boxes for the given image..
    #If the test image has path /content/gdrive/MyDrive/TEST_SET_YOLOV3/test_for_conf_mtx/test1.jpg
    #then its ground truth should be /content/gdrive/MyDrive/TEST_SET_YOLOV3/test_for_conf_mtx/test1.txt
    #in the same folder.
    annotation_file = filename[:filename.rindex('.')]+'.txt'

    #get each line from the .txt file and convert it into [class,xmin,ymin,xmax,ymax]
    #read each bbox line by line...
    #If there are no gt bboxes present in the image then append an empty list.
    file1 = open(annotation_file,'r')
    lines = file1.readlines() 

    #if there are some gt bounding boxes..
    if len(lines)!=0:
      #read each bounding box and store it..
      for line in lines: 
        temp1 = line
        templ = temp1.strip() #remove '\n'
        temp1 = temp1.split()

        class_of_bbox = int(temp1[0])
        xc_r = float(temp1[1])
        yc_r = float(temp1[2])
        wb_r = float(temp1[3])
        hb_r = float(temp1[4])

        xmin = int((xc_r - wb_r/2)*Image_Width)
        ymin = int((yc_r - hb_r/2)*Image_Height)
        xmax = int((xc_r+ wb_r/2)*Image_Width)
        ymax = int((yc_r+ hb_r/2)*Image_Height)
            

        cur_img_gt_bboxes.append([class_of_bbox, xmin, ymin, xmax, ymax])
          
    #if there are no ground truth bboxes then append an empty list..
    else :
      cur_img_gt_bboxes.append([])

    #collect the predicted bounding boxes for current image..
        

    #if there are some predicted bounding boxes for an image...
    if len(distro['objects']) != 0:
      # For every detection.
      for obj in range(len(distro['objects'])):
        # Get values.
        #frame_id = distro['frame_id']

        #get the class
        class_id = distro['objects'][obj]["class_id"]

        #get the xc_r
        xc_r = distro['objects'][obj]["relative_coordinates"]["center_x"]
        #get the yc_r
        yc_r = distro['objects'][obj]["relative_coordinates"]["center_y"]
        #get the wr
        wb_r = distro['objects'][obj]["relative_coordinates"]["width"]
        #get the hr
        hb_r = distro['objects'][obj]["relative_coordinates"]["height"]
        #get the prediction confidence
        confidence = distro['objects'][obj]["confidence"]

        xmin = int((xc_r - wb_r/2)*Image_Width)
        ymin = int((yc_r - hb_r/2)*Image_Height)
        xmax = int((xc_r+ wb_r/2)*Image_Width)
        ymax = int((yc_r+ hb_r/2)*Image_Height)
            
        # And save them.
        cur_img_pred_bboxes.append([xmin, ymin, xmax, ymax, confidence, class_id])

    #if there are no predicted bounding boxes then append an empty list..
    else :
      cur_img_pred_bboxes.append([])
        
        
    gt_bboxes.append(cur_img_gt_bboxes)
    pred_bboxes.append(cur_img_pred_bboxes)

  return (gt_bboxes , pred_bboxes)

def process_test(json_path, dest_path):
  '''
  json_path : @string
  dest_path : @string
  '''
  with open(json_path, 'r') as f:
    distros_dict = json.load(f)

  GT_BBOXES, PRED_BBOXES = get_data(distros_dict)

  labels = np.array([np.array([np.array(xi) for xi in GT_BBOXES[i]]) for i in range(len(GT_BBOXES))])
  detections = np.array([np.array([np.array(xi) for xi in PRED_BBOXES[i]]) for i in range(len(PRED_BBOXES))])

  #save the gt and detections into .npy format inside dest_path folder
  with open(os.path.join(dest_path, 'labels.npy'), 'wb') as f:
    np.save(f, labels)

  with open(os.path.join(dest_path, 'detections.npy'), 'wb') as f:
    np.save(f, detections)

  return